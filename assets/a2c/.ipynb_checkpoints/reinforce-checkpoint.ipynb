{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "permalink: /reinforce/\n",
    "layout: single\n",
    "author_profile: true\n",
    "title: Policy Gradient Theorem and REINFORCE\n",
    "folder: \"reinforce\"\n",
    "ipynb: \"reinforce.ipynb\"\n",
    "excerpt: ##########################\n",
    "header:\n",
    "  teaser: /assets/reinforce/######################\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "class VectorizedEnvWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, num_envs=1):\n",
    "        '''\n",
    "        env (gym.Env): to make copies of\n",
    "        num_envs (int): number of copies\n",
    "        '''\n",
    "        super().__init__(env)\n",
    "        self.num_envs = num_envs\n",
    "        self.envs = [copy.deepcopy(env) for n in range(num_envs)]\n",
    "    \n",
    "    def reset(self):\n",
    "        '''\n",
    "        Return and reset each environment\n",
    "        '''\n",
    "        return np.asarray([env.reset() for env in self.envs])\n",
    "    \n",
    "    def step(self, actions):\n",
    "        '''\n",
    "        Take a step in the environment and return the result.\n",
    "        actions (torch.tensor)\n",
    "        '''\n",
    "        next_states, rewards, dones = [], [], []\n",
    "        for env, action in zip(self.envs, actions):\n",
    "            next_state, reward, done, _ = env.step(action.item())\n",
    "            if done:\n",
    "                next_states.append(env.reset())\n",
    "            else:\n",
    "                next_states.append(next_state)\n",
    "            rewards.append(reward)\n",
    "            dones.append(done)\n",
    "        return np.asarray(next_states), np.asarray(rewards), \\\n",
    "            np.asarray(dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "class ValueEstimator:\n",
    "    def __init__(self, env, lr=1e-2):\n",
    "        self.N = env.observation_space.shape[0]\n",
    "        self.V = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.N, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1)\n",
    "        ).double()\n",
    "\n",
    "        self.opt = torch.optim.Adam(self.V.parameters(), lr=lr)\n",
    "        \n",
    "    def predict(self, s_t):\n",
    "        s_t = torch.tensor(s_t)\n",
    "        return self.V(s_t).squeeze()\n",
    "    \n",
    "    def learn(self, states, returns):\n",
    "        returns = torch.tensor(returns)\n",
    "        V_pred = self.predict(states)\n",
    "        \n",
    "        loss = torch.mean((V_pred - returns)**2)\n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        \n",
    "#         print(np.var(returns.numpy()))\n",
    "#         print(np.var((returns - V_pred).detach().numpy()))\n",
    "#         print()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    def pi(self, s_t):\n",
    "        '''\n",
    "        returns the probability distribution over actions \n",
    "        (torch.distributions.Distribution)\n",
    "        \n",
    "        s_t (np.ndarray): the current state\n",
    "        '''\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def act(self, s_t):\n",
    "        '''\n",
    "        s_t (np.ndarray): the current state\n",
    "        Because of environment vectorization, this will produce\n",
    "        E actions where E is the number of parallel environments.\n",
    "        '''\n",
    "        a_t = self.pi(s_t).sample()\n",
    "        return a_t\n",
    "    \n",
    "    def learn(self, states, actions, advantages):\n",
    "        '''\n",
    "        states (np.ndarray): the list of states encountered during\n",
    "                             rollout\n",
    "        actions (np.ndarray): the list of actions encountered during\n",
    "                              rollout\n",
    "        advantages (np.ndarray): the list of advantages encountered during\n",
    "                              rollout\n",
    "        \n",
    "        Because of environment vectorization, each of these has first\n",
    "        two dimensions TxE where T is the number of time steps in the\n",
    "        rollout and E is the number of parallel environments.\n",
    "        '''\n",
    "        actions = torch.tensor(actions)\n",
    "        advantages = torch.tensor(advantages)\n",
    "\n",
    "        log_prob = self.pi(states).log_prob(actions)\n",
    "        loss = torch.mean(-log_prob*advantages)\n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagonalGaussianPolicy(Policy):\n",
    "    def __init__(self, env, lr=1e-2):\n",
    "        '''\n",
    "        env (gym.Env): the environment\n",
    "        lr (float): learning rate\n",
    "        '''\n",
    "        self.N = env.observation_space.shape[0]\n",
    "        self.M = env.action_space.shape[0]\n",
    "        \n",
    "        self.mu = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.N, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, self.M)\n",
    "        ).double()\n",
    "\n",
    "        self.log_sigma = torch.ones(self.M, dtype=torch.double, requires_grad=True)\n",
    "\n",
    "        self.opt = torch.optim.Adam(list(self.mu.parameters()) + [self.log_sigma], lr=lr)\n",
    "        \n",
    "    def pi(self, s_t):\n",
    "        '''\n",
    "        returns the probability distribution over actions\n",
    "        s_t (np.ndarray): the current state\n",
    "        '''\n",
    "        s_t = torch.as_tensor(s_t).double()\n",
    "        mu = self.mu(s_t)\n",
    "        log_sigma = self.log_sigma\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        pi = torch.distributions.MultivariateNormal(mu, torch.diag(sigma))\n",
    "        return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalPolicy(Policy):\n",
    "    def __init__(self, env, lr=1e-2):\n",
    "        '''\n",
    "        env (gym.Env): the environment\n",
    "        lr (float): learning rate\n",
    "        '''\n",
    "        self.N = env.observation_space.shape[0]\n",
    "        self.M = env.action_space.n\n",
    "        self.p = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.N, self.M),\n",
    "        ).double()\n",
    "        \n",
    "        self.opt = torch.optim.Adam(self.p.parameters(), lr=lr)\n",
    "        \n",
    "    def pi(self, s_t):\n",
    "        '''\n",
    "        returns the probability distribution over actions\n",
    "        s_t (np.ndarray): the current state\n",
    "        '''\n",
    "        s_t = torch.as_tensor(s_t).double()\n",
    "        p = self.p(s_t)\n",
    "        pi = torch.distributions.Categorical(logits=p)\n",
    "        return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(rewards, dones, gamma):\n",
    "    result = np.empty_like(rewards)\n",
    "    result[-1] = rewards[-1]\n",
    "    for t in range(len(rewards)-2, -1, -1):\n",
    "        result[t] = rewards[t] + gamma*(1-dones[t])*result[t+1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "\n",
    "def A2C(env, agent, value_estimator, gamma=0.99, epochs=100, T=1000):    \n",
    "    # for learning    \n",
    "    states = np.empty((T, env.num_envs, agent.N))\n",
    "    if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "        # discrete action spaces only need to store a \n",
    "        # scalar for each action.\n",
    "        actions = np.empty((T, env.num_envs))\n",
    "    else:\n",
    "        # continuous action spaces need to store a \n",
    "        # vector for each eaction.\n",
    "        actions = np.empty((T, env.num_envs, agent.M))\n",
    "    rewards = np.empty((T, env.num_envs))\n",
    "    dones = np.empty((T, env.num_envs))\n",
    "    \n",
    "    # for plotting\n",
    "    totals = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        s_t = env.reset()\n",
    "\n",
    "        for t in range(T):\n",
    "            a_t = agent.act(s_t)\n",
    "            s_t_next, r_t, d_t = env.step(a_t)\n",
    "\n",
    "            # for learning\n",
    "            states[t] = s_t\n",
    "            actions[t] = a_t\n",
    "            rewards[t] = r_t\n",
    "            dones[t] = d_t\n",
    "\n",
    "            s_t = s_t_next\n",
    "        \n",
    "        returns = calculate_returns(rewards, dones, gamma)\n",
    "\n",
    "        value_estimator.learn(states, returns)\n",
    "        advantages = torch.tensor(returns) - value_estimator.predict(states)\n",
    "        agent.learn(states, actions, advantages)\n",
    "        \n",
    "        # for plotting\n",
    "        # average reward = total reward/number of episodes\n",
    "        totals.append(rewards.sum()/dones.sum())\n",
    "        print(f'{epoch}/{epochs}:{totals[-1]}\\r', end='')\n",
    "        \n",
    "    sns.lineplot(x=range(len(totals)), y=totals)\n",
    "            \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rl/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/100:200.05776397515529\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7648e8a2ae3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalue_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValueEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA2C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-f5e4f8527e6b>\u001b[0m in \u001b[0;36mA2C\u001b[0;34m(env, agent, value_estimator, gamma, epochs, T)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0ma_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0ms_t_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# for learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = VectorizedEnvWrapper(gym.make(\"CartPole-v0\"), num_envs=32)\n",
    "agent = CategoricalPolicy(env, lr=1e-1)\n",
    "value_estimator = ValueEstimator(env, lr=1e-3)\n",
    "agent = A2C(env, agent, value_estimator, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rl/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/20:32.435141256555586\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym_cartpole_swingup\n",
    "env = VectorizedEnvWrapper(gym.make(\"CartPoleSwingUp-v0\"), num_envs=512)\n",
    "agent = DiagonalGaussianPolicy(env, lr=1e-2)\n",
    "value_estimator = ValueEstimator(env, lr=1e-1)\n",
    "agent = A2C(env, agent, value_estimator, gamma=0.9999, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "def generate_gif(env, agent, filename, T=200):\n",
    "    frames = []\n",
    "    s_t = env.reset()\n",
    "    for t in range(T):\n",
    "        a_t = agent.act(s_t)\n",
    "        s_t, r_t, d_t = env.step(a_t)\n",
    "        frame = env.envs[0].render(mode='rgb_array')\n",
    "        frames.append(frame)\n",
    "\n",
    "    images_list = [Image.fromarray(frame) for frame in frames]\n",
    "    imageio.mimsave(f'{filename}.gif', frames, duration=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_gif(env, agent, 'cartpole-swingup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
